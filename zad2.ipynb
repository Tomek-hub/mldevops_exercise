{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transform for dataset - Normalizing with mean and std of Fashion MNIST\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]  # Normalize to [-1, 1] for grayscale\n",
    ")\n",
    "\n",
    "# Download and load the training and test data\n",
    "train_dataset = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 32), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Tanh(),  # Output is normalized to [-1, 1] matching the normalized input\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the input\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = x.view(-1, 1, 28, 28)  # Reshape back to image dimensions\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and the optimizer\n",
    "model = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_autoencoder(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for images, _ in train_loader:\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "\n",
    "# Testing function (to calculate the reconstruction loss on the test set)\n",
    "def test_autoencoder(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, images)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    return test_loss / len(test_loader)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_autoencoder(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss = test_autoencoder(model, test_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Function to display a few original and reconstructed images\n",
    "def visualize_reconstructions(model, data_loader, device, n=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, _ in data_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            break  # Take only the first batch\n",
    "\n",
    "    images = images.cpu().numpy()\n",
    "    outputs = outputs.cpu().numpy()\n",
    "\n",
    "    # Plot original and reconstructed images\n",
    "    fig, axes = plt.subplots(2, n, figsize=(15, 3))\n",
    "    for i in range(n):\n",
    "        # Original images\n",
    "        axes[0, i].imshow(images[i].squeeze(), cmap=\"gray\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "\n",
    "        # Reconstructed images\n",
    "        axes[1, i].imshow(outputs[i].squeeze(), cmap=\"gray\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize the reconstructions\n",
    "visualize_reconstructions(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
